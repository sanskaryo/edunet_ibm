{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814c2eae",
   "metadata": {},
   "source": [
    "# Accesing watsonx.ai via REST API\n",
    "\n",
    "In this lab, we will look into making HTTP requests to access [watsonx.ai's REST API](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html) (**note**: this is technically a python library that replicates the API) and learn how to use the functionality.  This lab explores only the generate REST endpoint. One hopes that this GA product will soon have a complete documented REST API. For this notebook, the `.env` file should have a two keys: `IBMCLOUD_API_KEY` that can be created using the [IBM Cloud console](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui#create_user_key) and `PROJECT_ID` which corresponds to the watsonx.ai project that will be used for the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5d00e",
   "metadata": {},
   "source": [
    "## HTTP request headers\n",
    "Headers contain parameter values that represent the metadata associated with an API requests and response. In the watsonx.ai SaaS service, an authorization token generated by the IAM service is required when making calls to the REST API. In the following example, the input credentials are used to obtain a token. This token is used to create an 'Authorization' header to validate your access using a \"Bearer\" token. Note that tokens requested in this way have a 1 hour lifetime.\n",
    "\n",
    "The 'Content-type' header in the request is added to tell the server or the browser which is serving the resource to the end user about the media type of the request. In this case, type of expected data as 'application/json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12703f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_key = \"\"\n",
    "api_endpoint = \"https://us-south.ml.cloud.ibm.com/ml/v1-beta/\"\n",
    "project_id = \"\"\n",
    "if api_key is None or project_id is None:\n",
    "    print(\"Ensure the .env file contains a IBM Cloud API key and watsonx.ai project id.\")\n",
    "else:\n",
    "    authenticator = IAMAuthenticator(api_key)\n",
    "    access_token = authenticator.token_manager.get_token()\n",
    "    headers={\"Authorization\": f\"Bearer {access_token}\",\n",
    "            \"Content-Type\":\"application/json\"}\n",
    "print(json.dumps(headers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ed0a8",
   "metadata": {},
   "source": [
    "## POST vs GET\n",
    "HTTP requests come in two flavors: GET and POST.  When using GET, data parameters are included in the URL and visible to everyone. However, when using POST, data is not displayed in the URL but is instead passed in the HTTP message body. \n",
    "\n",
    "GET requests are intended to retrieve data from a server and do not modify the server’s state. On the other hand, POST requests are used to send data to the server for processing and may modify the server’s state.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957d6d2",
   "metadata": {},
   "source": [
    "## POST requests with 'Generate' endpoint\n",
    "\n",
    "The generate endpoint \"{API_ENDPOINT}generation/text\" provides an interface for sending prompts to any model supported by watsonx.ai. The endpoint takes a parameter of `version` that is currently only `2023-05-29`. Given a text prompt as inputs, and required parameters, the selected model will attempt to complete the provide input and return \"generated_text\".\n",
    "\n",
    "Request body needs to include:\n",
    "- Model id (string): the id of the model\n",
    "- Inputs (string): prompt to generate completion\n",
    "- Parameters for the model (key-value pairs)\n",
    "- Project id (string): the id of the project to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "body={\n",
    "  \"model_id\": \"google/flan-ul2\",\n",
    "  \"input\": \"Write a short blog post for an advanced cloud service for large language models: This service is\",\n",
    "  \"parameters\": {\n",
    "      \"decoding_method\": \"greedy\",  \n",
    "      \"max_new_tokens\": 50,  \n",
    "      \"min_new_tokens\": 25\n",
    "  },\n",
    "  \"project_id\": project_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a3f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url=f\"{api_endpoint}generation/text?version=2023-05-29\" \n",
    "response=requests.post(url=url, headers=headers, json=body )\n",
    "print(\"JSON Response: \", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d18da-fb6f-4545-bf3c-e586390df718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model results: {json.dumps(response.json()['results'], indent = 2)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e4f10",
   "metadata": {},
   "source": [
    "### Lab Complete\n",
    "At the present time, using the [python library](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html) is the best window into the API for Foundation Models on watsonx.ai SaaS GA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
